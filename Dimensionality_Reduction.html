<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Ben Denis Shaffer" />


<title>Dimensionality_Reduction</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />
<link href="site_libs/ionicons-2.0.1/css/ionicons.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="ion ion-ios-pulse"></span>
     
    STATS 500
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="about_stl1.html">About</a>
    </li>
    <li>
      <a href="SLM.nb.html">Linear Regression</a>
    </li>
    <li>
      <a href="MLM.html">Multivariate Linear Regression</a>
    </li>
    <li>
      <a href="Diagnostics.html">Diagnostics</a>
    </li>
    <li>
      <a href="Robust_Regression.html">Robust Regression</a>
    </li>
    <li>
      <a href="Response_Transpormations.nb.html">Response Transformations</a>
    </li>
    <li>
      <a href="Predictor_Transfromations.html">Predictor Transformations</a>
    </li>
    <li>
      <a href="Variable_Selection.html">Variable Selection</a>
    </li>
    <li>
      <a href="Dimensionality_Reduction.html">Dimonsionality Reduction</a>
    </li>
    <li class="dropdown-header">Regularization</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="ion ion-ios-pulse"></span>
     
    STATS 503
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Overview</li>
    <li>
      <a href="overview_503.html"></a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-laptop"></span>
     
    STATS 506
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="about_comp.html">About</a>
    </li>
    <li>
      <a href="STATS_506_HW_1.html">HW_1</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-map"></span>
     
    BIOSTAT 696
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="about_spatial.html">About</a>
    </li>
    <li>
      <a href="BIOSTAT_HW_1.html">HW1</a>
    </li>
    <li>
      <a href="BIOSTAT_696_HW4.html">HW4</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://medium.com/@bendenisshaffer">
    <span class="fa fa-medium"></span>
     
    Blog
  </a>
</li>
<li>
  <a href="https://www.linkedin.com/in/ben-denis-shaffer-16291140">
    <span class="fa fa-linkedin"></span>
     
    LinkedIn
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Dimensionality_Reduction</h1>
<h4 class="author"><em>Ben Denis Shaffer</em></h4>
<h4 class="date"><em>December 8, 2016</em></h4>

</div>


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>The idea bahind dimensionality reduction is similar to that of other variable selection methods. Perhaps the distinction is that in the methods considered here the selection of a subset of variables is done independantly of the responce variable. In contrast the <span class="math inline">\(AIC\)</span> or <span class="math inline">\(R^2_{Adj}\)</span> used a measure of fit and balanced it with the number of variables. In the types of analysis considered here the responce playes no role.</p>
</div>
<div id="topics" class="section level1">
<h1>Topics</h1>
<ul>
<li>Principal Component Regression</li>
<li>Partial Least Squares</li>
</ul>
<div id="principal-component-regression" class="section level2">
<h2>Principal Component Regression</h2>
<p>The key idea behind PCA is that variation in a variable translates into information, and we want to use variables that have the greatest information. PCA takes the idea a bit further then just selectiong a subset of variables with the highest variances. Instead in PCA you construct new variables that are linear cominations of the given variables, but in a very particular manner. Here is what happens:</p>
<p>We take <span class="math inline">\(X = &lt;X_1, X_2, ..., X_p&gt;\)</span> where each R.V. is centered to have mean 0. Then we define <span class="math inline">\(Z_{i} = u_{i1}X_1 + u_{i2}X_2 + ... + u_{ip}X_p = u_{i}^TX\)</span> which is just a R.V. that is a linear combination of all the <span class="math inline">\(X&#39;s\)</span>. We are going to want to use <span class="math inline">\(Z_{i}\)</span> as a predictor, and so we engineer it to have a highest variance we can achieve. This maximization is subject to the vector <span class="math inline">\(u_{i}\)</span>. To get the first <span class="math inline">\(Z_{1}\)</span> we solve for <span class="math inline">\(u_{1}\)</span>.</p>
<p>maximize <span class="math display">\[Var(u_{1}^TX) = u_{1}^TVar(X)u_{1} = u_{1}^T \Sigma u_{1}\]</span> subject to <span class="math display">\[u_{1}^Tu_{1} = 1\]</span></p>
<p>To get the second <span class="math inline">\(Z_{2}\)</span> we solve for <span class="math inline">\(u_{2}\)</span>, with another constraint that will guarantee that <span class="math inline">\(cov(Z_{1},Z_{2}) = 0\)</span> so that there is no duplication of information.</p>
<p>maximize <span class="math display">\[Var(u_{2}^TX) = u_{2}^TVar(X)u_{2} = u_{2}^T \Sigma u_{2}\]</span> subject to <span class="math display">\[u_{2}^Tu_{2} = 1\]</span> and <span class="math display">\[cov(Z_{1},Z_{2}) = Cov(u_{1}^TX, u_{2}^TX) = u_{1}^TCov(X,X)u_{2} = u_{1}^T \Sigma u_{2}\]</span></p>
<p>It turns out that the solution is that <span class="math inline">\(u_{1}\)</span>, <span class="math inline">\(u_{2}\)</span> â€¦ <span class="math inline">\(u_{p}\)</span> are Eigenvectors corresponding to <span class="math inline">\(\lambda_{1} \geq \lambda_2 \geq ... \geq \lambda_p\)</span> which are ordered Eigenvalues of <span class="math inline">\(\Sigma = X^TX\)</span>. So we can get all of the <span class="math inline">\(Z_{i}&#39;s\)</span> by computing the Eigenvectors of the estimated variance covariance matrix of the predictors.</p>
<pre class="r"><code>library(faraway)
data(&quot;fat&quot;)
index &lt;- seq(10, 250, by=10)
train &lt;- fat[-index, -c(1, 3, 8)]
test &lt;- fat[index, -c(1, 3, 8)]</code></pre>
<p>First we do very basic PCA. We compute the principal components based on the training covariates on a scaled basis. Then we plot the scree plot to get an idea of how the components explain the variation. In the plot we are looking for a kink, since that suggests that the next component doesnâ€™t add a significant amount of explanatory power. In our plot there isnâ€™t a distinct kink. Perhaps 4 or 6 PCs would be an adequate choice for prediction.</p>
<pre class="r"><code>pctrain = prcomp(train[,-1], scale = TRUE)</code></pre>
<p>What we do however is we use all the possible reasonable numbers of PCs and compute RMSE for each, then choose one with the lowest RMSE achieved. Of course RMSE is computed using the training data. From the plot we see that 4 PCs is the clear minimizing choice. Thus we add this to our results. A criticism of this however would be that we are using information from the testing data, and thus corrupting the integrity of the validation.</p>
<pre class="r"><code>mod3 = pcr(siri ~ ., data = train)

par(mfrow = c(1,2))
plot(pctrain$sdev, type = &quot;l&quot;, main = &quot;PCR Scree Plot&quot;)
plot(RMSEP(mod3, newdata = test), main = &quot;PCR RMSE Plot&quot;)</code></pre>
<p><img src="Dimensionality_Reduction_files/figure-html/unnamed-chunk-4-1.png" width="1152" /></p>
<pre class="r"><code>pred3 = predict(mod3, test, ncomp = 4)
RMSE3 = sqrt(mean((test$siri - pred3)^2))
results[3,] &lt;- RMSE3
row.names(results)[3] &lt;- &quot;PCR&quot;
results</code></pre>
<pre><code>##             RMSE
## OLS     4.395559
## OLS+AIC 4.342456
## PCR     3.366292</code></pre>
<p>To keep the integrity of the modeling, we can use Cross-Validation. For this we use the full dataset and effectively repeat the PCR with different random validation sets. The scree plot is again not so helpful, and the RMSE plot doesnâ€™t give a very clear inflection point. Nonetheless we find that RMSE is minimized with 12 PCs and thus include this in our results. This CR-PSR results is lower then the OLS results, however it is greater then the one time validated PCR.</p>
<pre class="r"><code>set.seed(1)
dt = rbind(train,test)
pccv = prcomp(dt[,-1], scale = TRUE)

mod3cv = pcr(siri ~., data = dt, validation = &quot;CV&quot;)
cvRMSE = RMSEP(mod3cv, estimae = &quot;CV&quot;)

par(mfrow = c(1,2))
plot(pccv$sdev, type = &quot;l&quot;, main = &#39;CV-PCR Plot&#39;)
plot(cvRMSE, main = &quot;CV-PCR RMSE Plot&quot;)</code></pre>
<p><img src="Dimensionality_Reduction_files/figure-html/unnamed-chunk-5-1.png" width="1152" /></p>
<pre class="r"><code>pred3cv = predict(mod3cv, test, ncomp = 12)
RMSE3cv = sqrt(mean((test$siri - pred3cv)^2))

results[4,] &lt;- RMSE3cv
row.names(results)[4] &lt;- &quot;CV-PCR&quot;
results</code></pre>
<pre><code>##             RMSE
## OLS     4.395559
## OLS+AIC 4.342456
## PCR     3.366292
## CV-PCR  4.033212</code></pre>
</div>
<div id="partial-least-squares" class="section level2">
<h2>Partial Least Squares</h2>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
