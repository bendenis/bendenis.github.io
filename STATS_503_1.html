<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Ben Denis Shaffer" />


<title>Principal Component Analysis</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />
<link href="site_libs/ionicons-2.0.1/css/ionicons.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="ion ion-ios-pulse"></span>
     
    STATS 500
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="overview_501.html">Overview</a>
    </li>
    <li>
      <a href="SLR.html">Linear Regression</a>
    </li>
    <li>
      <a href="MLM.html">Multivariate Linear Regression</a>
    </li>
    <li>
      <a href="Diagnostics.html">Diagnostics</a>
    </li>
    <li>
      <a href="Robust_Regression.html">Robust Regression</a>
    </li>
    <li>
      <a href="Response_Transpormations.html">Response Transformations</a>
    </li>
    <li>
      <a href="Predictor_Transfromations.html">Predictor Transformations</a>
    </li>
    <li>
      <a href="Variable_Selection.html">Variable Selection</a>
    </li>
    <li>
      <a href="Dimensionality_Reduction.html">Dimensionality Reduction</a>
    </li>
    <li class="dropdown-header">Regularization</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="ion ion-ios-pulse"></span>
     
    STATS 503
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Overview</li>
    <li>
      <a href="overview_503.html"></a>
    </li>
    <li class="dropdown-header">Principal Component Analysis</li>
    <li>
      <a href="STATS_503_1.html"></a>
    </li>
    <li class="dropdown-header">Factor Analysis</li>
    <li>
      <a></a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-laptop"></span>
     
    STATS 506
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="overview_506.html">Overview</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-map"></span>
     
    BIOSTAT 696
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="overview_696.html">Overview</a>
    </li>
    <li>
      <a href="BIOSTAT_1.html">PM 2.5 Concentrations</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://medium.com/@bendenisshaffer">
    <span class="fa fa-medium"></span>
     
    Blog
  </a>
</li>
<li>
  <a href="https://www.linkedin.com/in/ben-denis-shaffer-16291140">
    <span class="fa fa-linkedin"></span>
     
    LinkedIn
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Principal Component Analysis</h1>
<h4 class="author"><em>Ben Denis Shaffer</em></h4>

</div>


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Principal Component Analysis (PCA) is an unsupervised dimention-reduction technique used on multidimentional numerical data. Dimention reduction can be useful in many ways including exploratory data analysis and regression. Using PCA you construct covariates out of the given covariates in a way that preserves as much information as possible. You can think of data as living in a multidimentional space. A lot of that space can be empty (think of a scatter plot with high correlation and empty corners). For a 2D space you can find a line which will be close to most of the data. PCA is a technique that solves this problem in high-dimentions too.</p>
<p>PCA gives you principal component directions that consist of weights. These weights allow you to construct the new covariates. If you have a responce variable you can use these covariates as predictors. This is called Principal Component Regression. For visualization you can chose 2 or three of the principal complonents and project the data onto that subspace that you found.</p>
</div>
<div id="topics" class="section level1">
<h1>Topics</h1>
<ul>
<li>PCA Algorithm</li>
<li>Visualization</li>
<li>Statistical Validity</li>
</ul>
</div>
<div id="pca-algorithm" class="section level1">
<h1>PCA Algorithm</h1>
<p>In Data Science the words algorithm and model are offten used interchangably, which is ok. It is however possible to make a distinction. If we are assuming something about the nature of relationships between variables then we are dealing with a model. For example regression analysis can be considered a model based technique because we are implicitly assuming a linear relationship. If on the other hand we are not assuming any relationship we are dealing with an algorithm. Algorithms are instructions for solving a set problem. PCA is exactly that.</p>
<div id="pca-problem" class="section level3">
<h3>PCA Problem</h3>
<p>In words the set problem that PCA solves is the following: Find a set of orthogonal linear combinations of variables that maximizes the variance of these linear combinations. A linear combination is just a weighted sum of the variables, which are vectors. In other words, given your variables, you construct other variables which are weighted sums of the ones you are given. You do it such that the constructed variables ahve the greatest variance possible, but making sure that resultant variables are uncorrelated.</p>
<p>Mathematically the problem is an optimization problem that can be formulated in the following way:</p>
<p>We have a list of random variables <span class="math inline">\(X = X_1, X_2, ... , X_p\)</span>, which is just a representation of data, with <span class="math inline">\(Var(X) = \Sigma\)</span>. We want to derive a list <span class="math inline">\(Z = Z_1, Z_2, ... Z_k\)</span> such that</p>
<p><span class="math display">\[Z_i = w_{1i}X_1 + w_{2i}X_2 + ... + w_{pi}X_p  = w_i^TX\]</span> So <span class="math inline">\(Z_i\)</span> which are caller <em>Pricipal Components</em> is a linear combination of <span class="math inline">\(X\)</span>, and the weights <span class="math inline">\(w_i\)</span> which are called <em>Principal Component Directions</em> have two constraints:</p>
<p><span class="math display">\[ w_i^Tw_i = 1 \ \forall i \\w_i^Tw_j = 0 \ \forall i\neq j \]</span></p>
<p>There will be a PC directions for each Principal Component and they can be put in a matrix where each PC direction is a column:</p>
<p><span class="math display">\[ W = \begin{pmatrix}
  w_{11} &amp; w_{12} &amp; \cdots &amp; w_{1k} \\
  w_{21} &amp; w_{22} &amp; \cdots &amp; w_{2k} \\
  \vdots  &amp; \vdots  &amp; \ddots &amp; \vdots  \\
  w_{p1} &amp; w_{p2} &amp; \cdots &amp; w_{pk} 
 \end{pmatrix} \]</span></p>
<p>This way you can write the list of PCs as <span class="math inline">\(Z = W^TX\)</span> and the constraints on <span class="math inline">\(W\)</span> is simply <span class="math inline">\(W^TW = I\)</span>.</p>
<p>The optimization problem is to find <span class="math inline">\(W\)</span> such that variance of each <span class="math inline">\(Z_i\)</span> is maximized sequentially. That means that we want to <span class="math inline">\(Z_1\)</span> to have the largest variance, <span class="math inline">\(Z_2\)</span> the second largest variance and so on. Since <span class="math inline">\(Z = W_TX\)</span></p>
<p><span class="math display">\[Var(Z) = Var(W^TX) = W^TVar(X)W = W^T\Sigma W\]</span></p>
<p>So the PCA problem becomes</p>
<p><span class="math display">\[ max \ W^T \Sigma W, \\ W^TW = I\]</span> Where you need to find the <span class="math inline">\(W\)</span> that solves this.</p>
</div>
<div id="analytical-pca-solution" class="section level3">
<h3>Analytical PCA Solution</h3>
<p>The solution involves setting up a Lagrangian and differentiating it with respect to <span class="math inline">\(W\)</span></p>
<p><span class="math display">\[ \mathscr{L}(W) = W^T\Sigma W - \Lambda(I - W^TW) \]</span> where <span class="math inline">\(\Lambda\)</span> is a diagonal matrix of lagrangian multipliers:</p>
<p><span class="math display">\[\Lambda = \begin{pmatrix}
  \lambda_{1} &amp; 0 &amp; \cdots &amp; 0 \\
  0 &amp; \lambda_{2} &amp; \cdots &amp; 0 \\
  \vdots  &amp; \vdots  &amp; \ddots &amp; \vdots  \\
  0 &amp; 0 &amp; \cdots &amp; \lambda_{p} 
 \end{pmatrix} \]</span></p>
<p>These are just sums of terms where <span class="math inline">\(w_i\)</span>s don’t cross multiply, which means each derivative will only contain the <span class="math inline">\(w_i\)</span> with respect to which the derivative is taken.</p>
<p>So for example you can focus on <span class="math inline">\(w_1\)</span> and the solution becomes <span class="math display">\[\mathscr{L}(w_1) = w_{1}^T\Sigma w_1 - \lambda_1(1 - w_{1}^Tw_1)\]</span> <span class="math display">\[\frac{\partial\mathscr{L}(w_1)}{\partial w_1} = 2\Sigma w_1 - 2\lambda_1w_1 = 0 \]</span> And so you get that</p>
<p><span class="math display">\[ \Sigma w_1 = \lambda_1 w_1 \]</span> Given the matrix <span class="math inline">\(\Sigma\)</span> this defines an eigenvalue <span class="math inline">\(\lambda_1\)</span> and <span class="math inline">\(w_1\)</span> is the corresponding eigenvector of the the <span class="math inline">\(\Sigma\)</span> matrix.</p>
<p>So the solution to PCA biols down to finding the Eigendecomposition</p>
<p><span class="math display">\[\Sigma = W^T\Lambda W\]</span></p>
<p>and then <span class="math inline">\(Z = W^TX\)</span></p>
</div>
<div id="computational-pca-solution" class="section level3">
<h3>Computational PCA Solution</h3>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
